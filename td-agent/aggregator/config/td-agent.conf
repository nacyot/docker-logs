<source>
  type forward
  port ::DATA_PORT::
  bind ::DATA_BIND::
</source>

<match logspout.**>
  # Tag container log
  type rewrite_tag_filter
  rewriterule1 container_name ^(.*)$ container.$1
</match>

<match journal.**>
  # Tag system log
  type rewrite_tag_filter
  rewriterule1 process_name ^(.*)$ system.$1
</match>

<match container.** system.**>
  # Classify format
  type rewrite_tag_filter
  rewriterule1 event ^.*?:.*?\t.*$ raw.formatted.${tag}.ltsv
  rewriterule2 event .+ finish.formatted.${tag}.unmatch
</match>

### Process LTSV format start ###
<match raw.formatted.**.ltsv>
  # Parse LTSV format
  type fields_parser
  parse_key event
  pattern ([^\t]+?):([^\t]+)
  remove_tag_prefix raw
</match>

<match formatted.**.ltsv>
  # Remove event key  
  type record_reformer
  remove_keys time
  tag finish.${tag}
</match>
### Process LTSV format end ###

<match finish.**>
  # Copy event to raw_event
  type record_reformer
  tag reformed.${tag}

  <record>
    log_type ${tag_parts[2]}
    raw_event ${event}
  </record>
</match>

<match reformed.**>
  type copy
  <store>
    # Forward to elasticsearch
    type forest
    subtype elasticsearch

    <template>
      # Type name can be system or container
      type_name ${tag_parts[4]} 
      type elasticsearch
      host ::ES_HOST::
      port ::ES_PORT::
      logstash_format true
      flush_interval ::FLUSH_INTERVAL::
    </template>
  </store>

  <store>
    # TODO: S3 forwarding
    type s3

    aws_key_id ::AWS_KEY_ID::
    aws_sec_key ::AWS_SECRET_KEY::
    s3_bucket ::AWS_BUCKET::
    s3_region ::AWS_REGION::
    s3_object_key_format %{path}%{time_slice}_%{index}.%{file_extension}
    path logs/
    buffer_path /var/log/fluent/s3

    time_slice_format %Y%m%d-%H
    time_slice_wait 10m
  </store>
</match>
